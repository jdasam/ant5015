{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scaper\n",
    "!pip install nussl\n",
    "!pip install git+https://github.com/source-separation/tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import data, viz\n",
    "import nussl\n",
    "# Prepare MUSDB\n",
    "data.prepare_musdb('~/.nussl/tutorial/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_params = nussl.STFTParams(window_length=512, hop_length=128, window_type='sqrt_hann')\n",
    "fg_path = \"~/.nussl/tutorial/\"\n",
    "train_data = data.on_the_fly(stft_params, transform=None, fg_path=fg_path, num_mixtures=1000, coherent_prob=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = train_data[0]\n",
    "viz.show_sources(item['sources'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musdb_train = nussl.datasets.MUSDB18(subsets='train', split=\"train\")\n",
    "musdb_valid = nussl.datasets.MUSDB18(subsets='train', split=\"valid\")\n",
    "musdb_test = nussl.datasets.MUSDB18(subsets='test')\n",
    "len(musdb_train), len(musdb_valid), len(musdb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item = musdb_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item['mix'].audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item['sources']['vocals'].audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(train_item['mix'].audio_data[:, :200000], rate=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 5\n",
    "\n",
    "dataset_path = \"~/.nussl/tutorial/\"\n",
    "\n",
    "trainset = data.on_the_fly(stft_params, transform=None, fg_path=dataset_path+\"/train\", num_mixtures=10000, duration=duration)\n",
    "item = trainset[200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(item['mix'].audio_data[:, :200000], rate=44100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Data\n",
    "- We have to transform nussl.core.AudioSignal into desired format\n",
    "    1. We want to make One Vs All separation system. Therefore, we have to combine the sources except target\n",
    "        - If you want to make vocal separator, you can mix drum, bass, and other as a single source\n",
    "        - If you want to make drum separator, you can mix vocal, bass, and other as a single source\n",
    "    2. We want to use spectrogram instead of waveform audio samples \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nussl.datasets import transforms as nussl_tfm\n",
    "\n",
    "item = trainset[0]\n",
    "sum_sources = nussl_tfm.SumSources([['bass', 'drums', 'other']])\n",
    "transformed_item = sum_sources(item)\n",
    "print(transformed_item['sources'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Magnitude Spectrogram np.abs(AudioSignal.stft())\n",
    "msa = nussl_tfm.MagnitudeSpectrumApproximation()\n",
    "\n",
    "item = trainset[0]\n",
    "\n",
    "transformed_item = msa(item)\n",
    "print(transformed_item.keys())\n",
    "print(transformed_item['source_magnitudes'].shape)\n",
    "\n",
    "plt.figure(figsize=(10,20))\n",
    "plt.subplot(4,1,1)\n",
    "plt.imshow(np.log10(transformed_item['source_magnitudes'][...,0]), origin='lower', aspect='auto')\n",
    "plt.subplot(4,1,2)\n",
    "plt.imshow(np.log10(transformed_item['source_magnitudes'][...,1]), origin='lower', aspect='auto')\n",
    "plt.subplot(4,1,3)\n",
    "plt.imshow(np.log10(transformed_item['source_magnitudes'][...,2]), origin='lower', aspect='auto')\n",
    "plt.subplot(4,1,4)\n",
    "plt.imshow(np.log10(transformed_item['source_magnitudes'][...,3]), origin='lower', aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = nussl_tfm.Compose([\n",
    "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
    "    nussl_tfm.MagnitudeSpectrumApproximation(),\n",
    "    nussl_tfm.IndexSources('source_magnitudes', 1),\n",
    "    nussl_tfm.ToSeparationModel(),\n",
    "])\n",
    "item = trainset[0]\n",
    "print(\"Before transforms\")\n",
    "for key in item:\n",
    "    print(key, type(item[key]))\n",
    "print(\"\\nAfter transforms\")\n",
    "item = tfm(item)\n",
    "for key in item:\n",
    "    print(key, type(item[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_params = nussl.STFTParams(window_length=512, hop_length=128, window_type='sqrt_hann')\n",
    "tfm = nussl_tfm.Compose([\n",
    "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
    "    nussl_tfm.MagnitudeSpectrumApproximation(),\n",
    "    nussl_tfm.IndexSources('source_magnitudes', 1),\n",
    "    nussl_tfm.ToSeparationModel(),\n",
    "])\n",
    "duration = 5\n",
    "trainset = data.on_the_fly(stft_params, \n",
    "                          transform=tfm, \n",
    "                          fg_path=dataset_path+\"/train\", \n",
    "                          num_mixtures=10000000,\n",
    "                          time_stretch=None,\n",
    "                          duration=duration)\n",
    "item = trainset[0]\n",
    "print(item.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
